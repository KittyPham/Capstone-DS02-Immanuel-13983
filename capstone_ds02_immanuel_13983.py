# -*- coding: utf-8 -*-
"""Capstone DS02_Immanuel_13983

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OMX0c1hXb3jn-GysdPy3iLWGYvK3sZ2N
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split


from sklearn.utils import resample
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.model_selection import GridSearchCV

# load dataset
df = pd.read_csv('ObesityDataSet.csv')

"""# EDA (Exploratory Data Analysis)"""

# menampilkan beberapa baris pertama
print("Head ObesityDataSet:")
display(df.head())

df.info()
print(f'Jumlah baris: {df.shape[0]}, jumlah kolom: {df.shape[1]}')

# untuk deskripsi statistik fitur numerik
print("Deskripsi Statistik Fitur Numerik:")
display(df.describe())

# untuk mengecek missing values
print("Missing Values per Kolom:")
display(df.isnull().sum().to_frame('missing_count'))

# untuk mengecek nilai unik per kolom
print("Unique Values per Kolom:")
display(df.nunique().to_frame('unique_count'))

# untuk mengecek duplikasi
dup_count = df.duplicated().sum()
print(f'Jumlah baris duplikat: {dup_count}')

# untuk melihat keseimbangan/distribusi kelas target
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='NObeyesdad', hue='NObeyesdad', order=df['NObeyesdad'].value_counts().index, palette='Set2', legend=False)
plt.xticks(rotation=45)
plt.title('Distribusi Kelas NObeyesdad')
plt.xlabel('Kelas')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.show()

# Boxplot untuk deteksi outlier kolom numerik
num_cols = ['Age', 'Height', 'Weight']
df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')
df[num_cols].plot(kind='box', subplots=True, layout=(1,3), figsize=(15,5))
plt.tight_layout()
plt.show()

"""**Kesimpulan EDA**

*   Dataset ObesityDataSet.csv memiliki 2111 baris dan 17 kolom.
*   Dari total 17 kolom, 14 kolom bertipe object, dan sisanya numerik.
*   Ditemukan missing values, unique values dan data duplikat yang perlu ditangani.
*   Distribusi kelas target NObeyesdad tampak tidak seimbang.
*   Terdapat outlier pada kolom numerik.

# Preprocessing Data
"""

# Ganti tanda '?' menjadi NaN agar bisa dideteksi sebagai missing value
df.replace('?', np.nan, inplace=True)

# Ubah kolom-kolom yang seharusnya numerik ke tipe float
numerical_columns = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']
for col in numerical_columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Cek tipe kolom dan tentukan kolom kategorikal dan numerik
categorical_cols = df.select_dtypes(include='object').columns.tolist()
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

# Untuk data kategorikal, isi missing value dengan modus (nilai terbanyak)
for col in categorical_cols:
    if df[col].isnull().sum() > 0:
        imputer = SimpleImputer(strategy='most_frequent')
        df[col] = imputer.fit_transform(df[[col]]).ravel()

# Untuk data numerik, isi missing value dengan median
for col in numeric_cols:
    if df[col].isnull().sum() > 0:
        imputer = SimpleImputer(strategy='median')
        df[col] = imputer.fit_transform(df[[col]])

# Hapus data duplikat
before = df.shape[0]
df.drop_duplicates(inplace=True)
after = df.shape[0]


print(f"Jumlah data sebelum hapus duplikat: {before}")
print(f"Jumlah data setelah hapus duplikat: {after}")
print(f"Jumlah data duplikat yang dihapus: {before - after}")

# Pastikan data numerik benar
num_cols = ['Age', 'Height', 'Weight']
df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')

# Tentukan batas sumbu y agar konsisten
y_limits = {}
for col in num_cols:
    min_val = df[col].min()
    max_val = df[col].max()
    y_limits[col] = (min_val, max_val)

# visualisasi data numerik sebelum menangani outlier
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, col in enumerate(num_cols):
    df[[col]].plot(kind='box', ax=axes[i])
    axes[i].set_title(f"{col} (sebelum)")
    axes[i].set_ylim(y_limits[col])
plt.tight_layout()
plt.show()

# Metode IQR untuk menghapus outlier dari kolom numerik
for col in num_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    df = df[(df[col] >= lower) & (df[col] <= upper)]

# Visualisasi boxplot setelah outlier ditangani
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, col in enumerate(num_cols):
    df[[col]].plot(kind='box', ax=axes[i])
    axes[i].set_title(f"{col} (setelah)")
    axes[i].set_ylim(y_limits[col])
plt.tight_layout()
plt.show()

# Encoding fitur kategorikal (selain target)
categorical_cols = df.select_dtypes(include='object').columns.tolist()
categorical_cols.remove('NObeyesdad')

# Label encoding untuk fitur kategorikal
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Encoding untuk target
target_encoder = LabelEncoder()
df['NObeyesdad'] = target_encoder.fit_transform(df['NObeyesdad'])
label_encoders['NObeyesdad'] = target_encoder

# Tampilkan hasil encode awal
print("Data setelah encoding:")
display(df.head())

# Heatmap korelasi
plt.figure(figsize=(16, 12))
sns.heatmap(
    df.corr(),
    annot=True,
    fmt=".2f",
    cmap='magma',
    linewidths=0.5,
    cbar_kws={"shrink": 0.8}
)
plt.title("Heatmap Korelasi antar Fitur", fontsize=16)
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(rotation=0, fontsize=10)
plt.tight_layout()
plt.show()

# Pisahkan fitur dan target
X = df.drop('NObeyesdad', axis=1)
y = df['NObeyesdad']

# Standarisasi fitur
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Visualisasi distribusi kelas sebelum SMOTE
sns.countplot(x=y, order=pd.Series(y).value_counts().index)
plt.title("Distribusi Kelas Sebelum SMOTE")
plt.xticks(rotation=45)
plt.show()

# Tangani ketidakseimbangan kelas dengan SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y)

# Distribusi kelas setelah SMOTE
sns.countplot(x=y_resampled, order=pd.Series(y_resampled).value_counts().index)
plt.title("Distribusi Kelas Setelah SMOTE")
plt.xticks(rotation=45)
plt.show()

# Split data menjadi data train dan test
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

print("Jumlah Data Train:", X_train.shape)
print("Jumlah Data Test:", X_test.shape)

"""Kesimpulan Preprocessing Data


*   Missing values diatasi dengan mengganti nilai "?" pada kolom kategorikal menggunakan modus dan numerik menggunakan median.
*   Semua fitur kategorikal telah dikonversi ke bentuk numerik menggunakan Label Encoding.
*   Data duplikat berhasil dihapus.
*   Data numerik telah dinormalisasi menggunakan StandardScaler supaya skala yang dimiliki seragam.
*   Menggunakan oversampling yaitu SMOTE untuk menangani distribusi kelas target yang tidak seimbang dan berhasil ditangani.
*   Melakukan pembagian dataset dengan proporsi data train dan data test dengan proporsi 80:20 yang nantinya akan digunakan saat langkah pemodelan.

# Pemodelan & Evaluasi
"""

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='rbf', probability=True, random_state=42)
}

# Dictionary untuk menyimpan hasil evaluasi
results = {}

for model_name, model in models.items():
    print(f"\n=== Model: {model_name} ===")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Hitung metrik
    acc  = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    rec  = recall_score(y_test, y_pred, average='weighted')
    f1   = f1_score(y_test, y_pred, average='weighted')

    # Simpan hasil
    results[model_name] = {
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1 Score": f1,
        "y_pred": y_pred
    }

    # Tampilkan classification report
    print(classification_report(y_test, y_pred, target_names=target_encoder.classes_))

# Plot confusion matrix untuk setiap model
for model_name, res in results.items():
    cm = confusion_matrix(y_test, res["y_pred"])
    plt.figure(figsize=(8,6))
    sns.heatmap(
        cm, annot=True, fmt='d', cmap='viridis',
        xticklabels=target_encoder.classes_,
        yticklabels=target_encoder.classes_
    )
    plt.title(f"Confusion Matrix â€“ {model_name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.tight_layout()
    plt.show()

# Konversi dictionary hasil ke DataFrame untuk tabel dan plot
results_df = pd.DataFrame(results).T[['Accuracy', 'Precision', 'Recall', 'F1 Score']]

# Visualisasi perbandingan metrik
palette = sns.color_palette("coolwarm", n_colors=4)  # Palet warna untuk 4 metrik
fig, ax = plt.subplots(figsize=(12, 6))

# Plot bar menggunakan DataFrame
results_df.plot(
    kind='bar',
    ax=ax,
    color=palette
)

# Tambahkan label angka di atas batang
for container in ax.containers:
    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)

# Kustomisasi plot
plt.title("Perbandingan Performa Model (Tanpa Hyperparameter Tuning)")
plt.ylabel("Skor")
plt.ylim(0, 1.05)  # Batas sumbu Y
plt.xticks(rotation=0)
plt.legend(loc='lower right')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# Tampilkan tabel hasil evaluasi
print("\nTabel Hasil Evaluasi Model:")
display(results_df)

"""Kesimpulan Pemodelan & Evaluasi


*   Pemodelan menggunakan 3 algoritma yaitu Logistic Regression, Random Forest, dan SVM
*   Ketiga pemodelan mendapatkan hasil yang bagus, dengan evaluasi terbaik kepada algoritma Random Forest, dilanjutkan dengan Logistic Regression, dan terakhir SVM

# Hyperparameter Tuning
"""

# Definisikan parameter grid untuk setiap model
param_grid = {
    'Logistic Regression': {
        'C': [0.01, 0.1, 1, 10, 100],  # Parameter regulasi, mengontrol kekuatan regularisasi (nilai kecil = regularisasi kuat)
        'penalty': ['l2'],             # Jenis penalti regulasi (L2 = Ridge)
        'solver': ['lbfgs']            # Algoritma optimasi
    },
    'Random Forest': {
        'n_estimators': [50, 100, 200],  # Jumlah pohon
        'max_depth': [None, 10, 20],     # Kedalaman maksimum pohon
        'min_samples_split': [2, 5]      # Minimum sampel untuk split
    },
    'SVM': {
        'C': [0.1, 1, 10],              # Parameter regulasi
        'kernel': ['linear', 'rbf'],     # Jenis kernel
        'gamma': ['scale', 'auto']       # Parameter gamma untuk kernel non-linear
    }
}

# Definisikan base models dengan random_state untuk reproduktifitas
base_models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'SVM': SVC(random_state=42)
}

# Menyimpan model hasil tuning dan evaluasinya
best_models = {}     # Menyimpan model terbaik
tuned_results = {}   # Menyimpan hasil evaluasi

# Loop untuk tuning dan evaluasi masing-masing model
for name in base_models:
    print(f"Tuning model: {name}")

    # Lakukan pencarian kombinasi hyperparameter terbaik menggunakan GridSearchCV
    grid = GridSearchCV(
        base_models[name],         # Model dasar yang akan dituning
        param_grid[name],          # Grid parameter yang akan diuji
        cv=5,                      # 5-fold cross validation
        scoring='f1_weighted',     # Skor evaluasi berdasarkan F1-score tertimbang
        n_jobs=-1                  # Gunakan semua core CPU
    )
    grid.fit(X_train, y_train)     # Latih GridSearch dengan data latih

    best_model = grid.best_estimator_   # Simpan model terbaik
    best_models[name] = best_model      # Simpan ke dictionary

    # Evaluasi ulang model terbaik
    y_pred = best_model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='weighted')
    rec = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    tuned_results[name] = {
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1 Score": f1,
        "y_pred": y_pred
    }

    print(f"Best Params: {grid.best_params_}")
    print(classification_report(y_test, y_pred, target_names=target_encoder.classes_))
    print("="*60)

# Menampilkan confusion matrix dari model hasil tuning
for model_name, model in best_models.items():
    y_pred = tuned_results[model_name]["y_pred"]
    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_encoder.classes_,
                yticklabels=target_encoder.classes_)
    plt.title(f"Confusion Matrix (Setelah Tuning) - {model_name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.tight_layout()
    plt.show()

# Buat DataFrame dari tuned_results
results_df = pd.DataFrame({
    model_name: {
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1 Score': metrics['F1 Score']
    } for model_name, metrics in tuned_results.items()
}).T  # Transpose agar model menjadi baris

# Visualisasi perbandingan metrik
palette = sns.color_palette("coolwarm", n_colors=4)  # Palet warna untuk 4 metrik
fig, ax = plt.subplots(figsize=(12, 6))

# Plot bar menggunakan DataFrame
results_df.plot(
    kind='bar',
    ax=ax,
    color=palette
)

# Tambahkan label angka di atas batang
for container in ax.containers:
    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)

# Kustomisasi plot
plt.title("Perbandingan Performa Model (Setelah Hyperparameter Tuning)")
plt.ylabel("Skor")
plt.ylim(0, 1.05)  # Batas sumbu Y
plt.xticks(rotation=0)
plt.legend(loc='lower right')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""Kesimpulan


*   Setelah dilakukan hyperparameter tuning, meningkatkan hasil dari ketiga model
*   Penaikan terbesar terjadi pada model Logistic Regression yang mendapatkan peningkatan 7% dari 86 menjadi 93
*   Random Forest tetap menjadi model terbaik dari sebelum dilakukan hyperparameter tuning maupun setelah dilakukan hyperparameter tuning
*   Performa dari model Logistic Regression dan SVM meningkat cukup signifikan setelah dilakukan hyperparameter tuning. Dari yang sebelumnya sebesar 86% dan 89% menjadi 93% dan 95%.




"""